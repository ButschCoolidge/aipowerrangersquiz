{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80MHbkZGF_mV"
      },
      "source": [
        "# Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsBaBTxHahcw"
      },
      "outputs": [],
      "source": [
        "interactive_gui = True\n",
        "\n",
        "# blog post and paper used width=16\n",
        "width = 8\n",
        "# width = 16\n",
        "\n",
        "depth = 2\n",
        "\n",
        "# the ratio of the number of training datapoints to the number of free\n",
        "# dimensions in the neural network\n",
        "# dataset_param_multiple = 10 # still looks like a fractal, but a boring one\n",
        "# dataset_param_multiple = 0.5\n",
        "dataset_param_multiple = 1.\n",
        "# dataset_param_multiple = 'single_datapoint'\n",
        "\n",
        "minibatch_size = None # full batch training\n",
        "# minibatch_size = 16\n",
        "\n",
        "# the dimension of the targets for regression (the y variables)\n",
        "target_dim = 1\n",
        "# target_dim = width\n",
        "\n",
        "nonlinearity = 'tanh'\n",
        "# nonlinearity = 'relu'\n",
        "# nonlinearity = 'identity'\n",
        "\n",
        "phase_space = 'lr_vs_lr'\n",
        "# phase_space = 'paraminit_vs_lr'\n",
        "\n",
        "readout = 'loss'\n",
        "# readout = 'probe_point'\n",
        "\n",
        "# blog post and paper used opt_steps=500 or opt_steps=1000 for experiments\n",
        "opt_steps = 100\n",
        "# opt_steps = 500\n",
        "# opt_steps = 1000\n",
        "\n",
        "# the default resolution to use when generating loss landscape visualizations.\n",
        "# for final products, this should be much larger! e.g. 4096.\n",
        "default_resolution = 512\n",
        "# default_resolution = 4096\n",
        "\n",
        "# figure size, and dpi to use when saving figures.\n",
        "# (this is mostly overwritten for specific use cases, e.g. saving video. check\n",
        "# the load_and_generate(...) function)\n",
        "dpi = 100\n",
        "figsize = (8,8)\n",
        "# figsize = (4.5,4.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4xkntX42nf2"
      },
      "outputs": [],
      "source": [
        "def canonical_name():\n",
        "  \"\"\"\n",
        "  turn hyperparameters in the previous cell into a canonical base filename to\n",
        "  use for this experimental condition\n",
        "  \"\"\"\n",
        "  return f'zoom_sequence_width-{width}_depth-{depth}_datasetparamratio-{dataset_param_multiple}_minibatch-{minibatch_size}_nonlinearity-{nonlinearity}_phasespace-{phase_space}{\"_readout-probe_point\" if readout == \"probe_point\" else \"\"}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzznsE3YF6Cd"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkNXYnK1uREs"
      },
      "outputs": [],
      "source": [
        "image_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoydUuNH7iao"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import config\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import cm\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "import datetime\n",
        "\n",
        "import pickle\n",
        "\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuubXRfMy26A"
      },
      "outputs": [],
      "source": [
        "# so that results can be saved directly to Google Drive, rather than being lost when the colab kernel stops\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnVLkfFCBo4i"
      },
      "outputs": [],
      "source": [
        "## tool for computing fractal dimension\n",
        "!pip install git+https://github.com/PMEAL/porespy.git\n",
        "import porespy as ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMU1bvu9Y20d"
      },
      "outputs": [],
      "source": [
        "if interactive_gui:\n",
        "  ## interactive plotting\n",
        "  !pip install ipympl\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "  %matplotlib ipympl\n",
        "else:\n",
        "  matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyrimeH8GCKi"
      },
      "source": [
        "# Network and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjeFMB_L7oYT"
      },
      "outputs": [],
      "source": [
        "def net(theta, X):\n",
        "  # mean field parameterization\n",
        "  for W in theta:\n",
        "    Z = jnp.dot(X, W)/jnp.sqrt(W.shape[0])\n",
        "    if nonlinearity == 'tanh':\n",
        "      X = jax.nn.tanh(Z*jnp.sqrt(2))\n",
        "    elif nonlinearity == 'relu':\n",
        "      X = jax.nn.relu(Z)*jnp.sqrt(2)\n",
        "    elif nonlinearity == 'identity':\n",
        "      X = Z\n",
        "    else:\n",
        "      assert False\n",
        "  return Z /jnp.sqrt(W.shape[0])\n",
        "\n",
        "def init(rng, width, depth):\n",
        "  rng = jax.random.split(rng, depth)\n",
        "  theta = []\n",
        "  out_width = width\n",
        "  for i in range(depth):\n",
        "    if i == depth-1:\n",
        "      out_width = target_dim\n",
        "    W = jax.random.normal(rng[i], (width, out_width))\n",
        "    theta.append(W)\n",
        "  return theta\n",
        "\n",
        "def loss(theta, X, Y):\n",
        "  Z = net(theta, X)\n",
        "  return jnp.mean((Z - Y)**2)\n",
        "\n",
        "def hparams_f(hparams, theta):\n",
        "  \"\"\"\n",
        "  convert hyperparameters into a learning rate for each layer in the network\n",
        "  \"\"\"\n",
        "  lr = []\n",
        "  for i, t in enumerate(theta):\n",
        "    lr.append(hparams[i%len(hparams)])\n",
        "  return lr\n",
        "\n",
        "def train_step(rng, theta, hparams, X, Y):\n",
        "  if phase_space == 'lr_vs_lr':\n",
        "    learning_rates = hparams_f(hparams, theta)\n",
        "  elif phase_space == 'paraminit_vs_lr':\n",
        "    new_theta = []\n",
        "    for i, t in enumerate(theta):\n",
        "      if i == 0:\n",
        "        t += hparams[0]\n",
        "      new_theta += [t]\n",
        "    theta = new_theta\n",
        "    learning_rates = hparams_f([hparams[1]], theta)\n",
        "  else:\n",
        "    assert False, f'invalid phase space {phase_space}'\n",
        "\n",
        "  if minibatch_size is None:\n",
        "    _loss, _grad = jax.value_and_grad(loss)(theta, X, Y)\n",
        "  else:\n",
        "    idx = jax.random.randint(rng, (minibatch_size,), 0, X.shape[0])\n",
        "    _X = X[idx]\n",
        "    _Y = Y[idx]\n",
        "    # evaluate loss on full batch for smooth visualization\n",
        "    _loss = loss(theta, X, Y)\n",
        "    _grad = jax.grad(loss)(theta, _X, _Y)\n",
        "\n",
        "  if readout == 'probe_point':\n",
        "    srng = jax.random.PRNGKey(-1234567)\n",
        "    X_probe = jax.random.normal(srng, (1, X.shape[1]))\n",
        "    tracked_value = net(theta, X_probe).ravel()[0]\n",
        "  elif readout == 'loss':\n",
        "    tracked_value = _loss\n",
        "\n",
        "  return jax.tree_map(lambda t, g, lr: t - lr*g, theta, _grad, learning_rates), tracked_value\n",
        "\n",
        "train_step_lrvmap = jax.jit(\n",
        "    jax.vmap(train_step, in_axes=(None, 0, 0, None, None), out_axes=(0,0)),\n",
        "    donate_argnums=(0,1))\n",
        "\n",
        "def train(theta, hparams, X, Y, num_steps, outer_batch_size=50000):\n",
        "\n",
        "  bs = hparams.shape[0]\n",
        "\n",
        "  if bs > outer_batch_size:\n",
        "    # split up the hyperparameter search grid if we would run out of memory\n",
        "    return jnp.concatenate(\n",
        "        (train(theta, hparams[:bs//2], X, Y, num_steps),\n",
        "        train(theta, hparams[bs//2:], X, Y, num_steps)),\n",
        "        axis=0)\n",
        "\n",
        "  rng = jax.random.PRNGKey(42)\n",
        "  rng = jax.random.split(rng, num_steps)\n",
        "  losses = []\n",
        "  _theta = jax.tree_map(lambda u: jnp.tile(u, (bs,) + (1,)*len(u.shape)), theta)\n",
        "  for _rng in rng:\n",
        "    _theta, _loss = train_step_lrvmap(_rng, _theta, hparams, X, Y)\n",
        "    losses.append(_loss)\n",
        "\n",
        "  return convergence_measure_vmap(jnp.stack(losses, axis=-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMqMOauPGVaV"
      },
      "source": [
        "# Analysis and plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXd_k577GSRl"
      },
      "source": [
        "## Train networks over grid of hyperparameter values and generate image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3uRGYizxrNw"
      },
      "outputs": [],
      "source": [
        "# @jax.jit\n",
        "def convergence_measure(v, max_val = 1e6):\n",
        "  \"\"\"\n",
        "  turn the training trajectory into a single number which looks pretty in an\n",
        "  image\n",
        "  \"\"\"\n",
        "\n",
        "  fin = jnp.isfinite(v)\n",
        "  v = v*fin + max_val*(1-fin)\n",
        "\n",
        "  if readout == 'probe_point':\n",
        "    # return the final value of the function, at the end of training\n",
        "    return v[-1]\n",
        "\n",
        "  assert readout == 'loss', 'invalid readout type'\n",
        "\n",
        "  v /= v[0]\n",
        "  exceeds = (v > max_val)\n",
        "  v = v*(1-exceeds) + max_val*exceeds\n",
        "\n",
        "  converged = (jnp.mean(v[-20:]) < 1) # average over any oscillatory behavior\n",
        "  return jnp.where(converged, -jnp.sum(v), jnp.sum(1/v))\n",
        "\n",
        "convergence_measure_vmap = jax.jit(jax.vmap(convergence_measure, in_axes=(0,), out_axes=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_NNRyZcQe6k"
      },
      "outputs": [],
      "source": [
        "def gen_img(mnmx, resolution=None):\n",
        "  \"\"\"\n",
        "  generate an image of the hyperparameter landscape,\n",
        "  for a range of hyperparameter values specified by mnmx\n",
        "  \"\"\"\n",
        "\n",
        "  if resolution is None:\n",
        "    resolution = default_resolution\n",
        "\n",
        "  mn1, mx1, mn2, mx2 = mnmx\n",
        "  rng = jax.random.PRNGKey(0)\n",
        "  rng, srng = jax.random.split(rng)\n",
        "  theta = init(srng, width, depth)\n",
        "\n",
        "  n_params = jnp.sum(jnp.array(jax.tree_map(lambda u: u.size, theta)))\n",
        "\n",
        "  rng, srng = jax.random.split(rng)\n",
        "\n",
        "  if dataset_param_multiple == 'single_datapoint':\n",
        "    batch_size = 1\n",
        "  else:\n",
        "    if nonlinearity == 'identity':\n",
        "      batch_size = int(width*dataset_param_multiple)\n",
        "    else:\n",
        "      batch_size = int(n_params*dataset_param_multiple/target_dim)\n",
        "\n",
        "  X = jax.random.normal(srng, (batch_size, width))\n",
        "  rng, srng = jax.random.split(rng)\n",
        "  Y = jax.random.normal(srng, (batch_size, target_dim))\n",
        "\n",
        "  gg1 = jnp.logspace(mn1, mx1, resolution)\n",
        "  gg2 = jnp.logspace(mn2, mx2, resolution)\n",
        "  lr0, lr1 = jnp.meshgrid(gg2, gg1)\n",
        "  lr = jnp.stack([lr0.ravel(), lr1.ravel()], axis=-1)\n",
        "\n",
        "  V = train(theta, lr, X, Y, opt_steps)\n",
        "\n",
        "  return V.reshape((resolution, resolution))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6m59F_J3VIq"
      },
      "source": [
        "## Fractal dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvZAN8ZAvdEo"
      },
      "outputs": [],
      "source": [
        "def extract_edges(X):\n",
        "  \"\"\"\n",
        "  define edges as sign changes in the scalar representing convergence or\n",
        "  divergence rate -- on one side of the edge training converges,\n",
        "  while on the other side of the edge training diverges\n",
        "  \"\"\"\n",
        "\n",
        "  Y = jnp.stack((X[1:,1:], X[:-1,1:], X[1:,:-1], X[:-1,:-1]), axis=-1)\n",
        "  Z = jnp.sign(jnp.max(Y, axis=-1)*jnp.min(Y, axis=-1))\n",
        "  return Z<0\n",
        "\n",
        "def estimate_fractal_dimension(hist_video, show_plot=True):\n",
        "  edges = [extract_edges(U[0]) for U in hist_video]\n",
        "  box_counts = [ps.metrics.boxcount(U) for U in edges]\n",
        "  all_images = np.concatenate([bc.slope for bc in box_counts])\n",
        "\n",
        "  if show_plot:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    ax1.set_yscale('log')\n",
        "    ax1.set_xscale('log')\n",
        "    ax1.set_xlabel('box edge length')\n",
        "    ax1.set_ylabel('number of boxes spanning phases')\n",
        "    ax2.set_xlabel('box edge length')\n",
        "    ax2.set_ylabel('image')\n",
        "    ax2.set_xscale('log')\n",
        "\n",
        "    for bc in box_counts:\n",
        "      ax1.plot(bc.size, bc.count,'-o')\n",
        "      ax2.plot(bc.size, bc.slope,'-o');\n",
        "\n",
        "  mfd = np.median(all_images)\n",
        "  print(f'median fractal dimension estimate {mfd}')\n",
        "\n",
        "  return mfd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWglSNX_4SoS"
      },
      "source": [
        "## Image restretch to use full color palette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ezo5g6Rx2q9"
      },
      "outputs": [],
      "source": [
        "def cdf_img(x, x_ref, buffer=0.25):\n",
        "  \"\"\"\n",
        "  rescale x, relative to x_ref (x_ref is often the same as x), to achieve a uniform\n",
        "  distribution over values with positive and negative intensities, but also to\n",
        "  preserve the sign of x. This makes for a visualization that shows more\n",
        "  structure.\n",
        "  \"\"\"\n",
        "\n",
        "  u = jnp.sort(x_ref.ravel())\n",
        "\n",
        "  if readout == 'probe_point':\n",
        "    v = jnp.linspace(-1, 1, u.shape[0])\n",
        "  elif readout == 'loss':\n",
        "    num_neg = jnp.sum(u<0)\n",
        "    num_nonneg = u.shape[0] - num_neg\n",
        "    v = jnp.concatenate((jnp.linspace(-1,-buffer,num_neg), jnp.linspace(buffer,1,num_nonneg)), axis=0)\n",
        "  else:\n",
        "    assert False, 'invalid readout'\n",
        "\n",
        "  y = jnp.interp(x, u, v)\n",
        "  return -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt5U0NYI4bdX"
      },
      "source": [
        "## Code for (interactive) figure display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObAjIKt9FfIw"
      },
      "outputs": [],
      "source": [
        "def truncate_sci_notation(numbers):\n",
        "  \"\"\"\n",
        "  keeping enough significant digits that the\n",
        "  numbers disagree in four digits\n",
        "  \"\"\"\n",
        "\n",
        "  # Convert numbers to scientific notation\n",
        "  n1_sci, n2_sci = \"{:.15e}\".format(numbers[0]), \"{:.15e}\".format(numbers[1])\n",
        "\n",
        "  # Extract the significant parts and exponents\n",
        "  sig_n1, exp_n1 = n1_sci.split('e')\n",
        "  sig_n2, exp_n2 = n2_sci.split('e')\n",
        "\n",
        "  # Find the first position at which they disagree\n",
        "  min_len = min(len(sig_n1), len(sig_n2))\n",
        "  truncate_index = min_len\n",
        "\n",
        "  for i in range(min_len):\n",
        "      if (sig_n1[i] != sig_n2[i]) or (exp_n1 != exp_n2):\n",
        "          # +4 accounts for 4 digits after the first disagreement\n",
        "          truncate_index = i + 4\n",
        "          if i == 0:\n",
        "            truncate_index += 1 # Account for decimal point\n",
        "          break\n",
        "\n",
        "  exp_n1 = exp_n1[0] + exp_n1[2]\n",
        "  exp_n2 = exp_n2[0] + exp_n2[2]\n",
        "  if (exp_n1 == \"+00\") and (exp_n2 == \"+00\"):\n",
        "    # don't bother with scientific notation if exponent is 0\n",
        "    return [sig_n1[:truncate_index], sig_n2[:truncate_index]]\n",
        "\n",
        "  # Truncate and reconstruct the scientific notation\n",
        "  truncated_n1 = \"{}e{}\".format(sig_n1[:truncate_index], exp_n1)\n",
        "  truncated_n2 = \"{}e{}\".format(sig_n2[:truncate_index], exp_n2)\n",
        "\n",
        "  return [truncated_n1, truncated_n2]\n",
        "\n",
        "def tickslabels(mnmx):\n",
        "  return mnmx, truncate_sci_notation(10.**np.array(mnmx))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX8PAo5ZGZRt"
      },
      "outputs": [],
      "source": [
        "cids = []\n",
        "click_event = [None]\n",
        "\n",
        "def onclick(event):\n",
        "  click_event[0] = (event.xdata, event.ydata)\n",
        "\n",
        "def onrelease(event, fig, im, rect, mnmx, img, recalculate_image=True):\n",
        "  if click_event[0] is None:\n",
        "    return\n",
        "\n",
        "  e0 = [click_event[0][0], event.xdata]\n",
        "  e1 = [click_event[0][1], event.ydata]\n",
        "\n",
        "  for v in e0+e1:\n",
        "    if v is None:\n",
        "      return\n",
        "\n",
        "  newmnmx = [np.min(e1), np.max(e1), np.min(e0), np.max(e0)]\n",
        "\n",
        "  min_w = (mnmx[1] - mnmx[0])/20\n",
        "  if newmnmx[1] - newmnmx[0] < min_w:\n",
        "    c = (newmnmx[1] + newmnmx[0])/2.\n",
        "    newmnmx[0] = c - min_w/2\n",
        "    newmnmx[1] = c + min_w/2\n",
        "  min_w = (mnmx[3] - mnmx[2])/20\n",
        "  if newmnmx[1] - newmnmx[0] < min_w:\n",
        "    c = (newmnmx[3] + newmnmx[2])/2.\n",
        "    newmnmx[2] = c - min_w/2\n",
        "    newmnmx[3] = c + min_w/2\n",
        "\n",
        "  for v in newmnmx:\n",
        "    if v is None:\n",
        "      return\n",
        "  plot_img(img, mnmx, newmnmx, fig=fig, im=im, rect=rect)\n",
        "  plt.draw()\n",
        "\n",
        "  if recalculate_image:\n",
        "    click_event[0] = None\n",
        "    mnmx = newmnmx\n",
        "    img = gen_img(mnmx)\n",
        "    plot_img(img, mnmx, None, fig=fig, im=im, rect=rect)\n",
        "\n",
        "def plot_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n",
        "             handler=True, savename=None,\n",
        "             reference_scale=None,\n",
        "             cmap='Spectral',\n",
        "             title=\"\"\n",
        "             ):\n",
        "  mn1, mx1, mn2, mx2 = mnmx\n",
        "\n",
        "  if reference_scale is None:\n",
        "    reference_scale = image\n",
        "\n",
        "  image = cdf_img(image, reference_scale)\n",
        "\n",
        "  ax1 = None\n",
        "  if fig is None:\n",
        "    fig, (ax1) = plt.subplots(figsize=figsize, dpi=dpi)\n",
        "    im = ax1.imshow(image,\n",
        "                    extent=[mn2, mx2, mn1, mx1],\n",
        "                    origin='lower',\n",
        "                    vmin=-1, vmax=1,\n",
        "                    cmap=cmap,\n",
        "                    aspect='auto',\n",
        "                    interpolation='nearest'\n",
        "                    )\n",
        "    if title is None:\n",
        "      batch_text = \"full batch\" if minibatch_size is None else \"minibatch\"\n",
        "      if dataset_param_multiple == 'single_datapoint':\n",
        "        batch_text = 'single training point'\n",
        "      title = f'Trainability dependence on {\"per-layer learning rates\" if phase_space == \"lr_vs_lr\" else \"parameter initialization and learning rate\"}\\n1 hidden layer, {nonlinearity}, {batch_text}'\n",
        "    if not title == \"\":\n",
        "      plt.title(title)\n",
        "    if phase_space == 'lr_vs_lr':\n",
        "      ax1.set_ylabel('Output layer learning rate')\n",
        "      ax1.set_xlabel('Input layer learning rate')\n",
        "    elif phase_space == 'paraminit_vs_lr':\n",
        "      ax1.set_ylabel('Learning rate')\n",
        "      ax1.set_xlabel('Input layer weight offset')\n",
        "\n",
        "    rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n",
        "    ax1.add_patch(rect)\n",
        "\n",
        "  im.set_extent([mn2, mx2, mn1, mx1])\n",
        "  im.set_data(image)\n",
        "\n",
        "  # Set the new tick positions on the x-axis\n",
        "  aaxx = plt.gca()\n",
        "  aaxx.set_xticks(*tickslabels([mn2, mx2]))\n",
        "  aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n",
        "\n",
        "  labels = aaxx.get_xticklabels()\n",
        "  labels[0].set_horizontalalignment('left')\n",
        "  labels[1].set_horizontalalignment('right')\n",
        "  labels = aaxx.get_yticklabels()\n",
        "  labels[0].set_verticalalignment('bottom')\n",
        "  labels[1].set_verticalalignment('top')\n",
        "\n",
        "  if handler and (newmnmx is None):\n",
        "    image_history.append((image, mnmx))\n",
        "\n",
        "  if newmnmx:\n",
        "    mn1, mx1, mn2, mx2 = newmnmx\n",
        "  rect.set_xy((mn2, mn1))\n",
        "  rect.set_width(mx2-mn2)\n",
        "  rect.set_height(mx1-mn1)\n",
        "\n",
        "  if handler:\n",
        "    while len(cids) > 0:\n",
        "      fig.canvas.mpl_disconnect(cids.pop())\n",
        "\n",
        "    def onrelease_partial(event):\n",
        "      return onrelease(event, fig, im, rect, mnmx, img)\n",
        "    def onmotion_partial(event):\n",
        "      return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n",
        "\n",
        "    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n",
        "    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n",
        "    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.draw()\n",
        "\n",
        "  if savename:\n",
        "    plt.savefig(savename)\n",
        "\n",
        "  return fig, ax1, im\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgXlmdmQG9Pz"
      },
      "source": [
        "## Animate fractal zoom sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmYjS4szbFN1"
      },
      "outputs": [],
      "source": [
        "def zoom_out_sequence(hist_final, growth_factor=2., max_scale=6):\n",
        "  \"\"\"\n",
        "  generate a sequence of (image, bounds) zooming out from the (image, bounds) in hist_final\n",
        "  \"\"\"\n",
        "\n",
        "  image, mnmx = hist_final\n",
        "\n",
        "  cT = np.array([(mnmx[0] + mnmx[1])/2., (mnmx[2] + mnmx[3])/2.])\n",
        "  wT = np.array([mnmx[1] - mnmx[0], mnmx[3] - mnmx[2]])\n",
        "\n",
        "  hist = [(image, mnmx)]\n",
        "  w_scale = 1.\n",
        "  if np.min(wT * w_scale) >= max_scale:\n",
        "      w_scale *= growth_factor\n",
        "      new_mnmx = [\n",
        "          cT[0] - w_scale * wT[0]/2.,\n",
        "          cT[0] + w_scale * wT[0]/2.,\n",
        "          cT[1] - w_scale * wT[1]/2.,\n",
        "          cT[1] + w_scale * wT[1]/2.,\n",
        "      ]\n",
        "      hist.insert(0, (np.zeros((2,2)), new_mnmx))\n",
        "\n",
        "\n",
        "  while np.min(wT * w_scale) < max_scale:\n",
        "    w_scale *= 2\n",
        "    mnmx = [\n",
        "        cT[0] - w_scale * wT[0]/2.,\n",
        "        cT[0] + w_scale * wT[0]/2.,\n",
        "        cT[1] - w_scale * wT[1]/2.,\n",
        "        cT[1] + w_scale * wT[1]/2.,\n",
        "    ]\n",
        "    hist.insert(0, (np.zeros((2,2)), mnmx))\n",
        "\n",
        "  return hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_RJ_8GyyuOj"
      },
      "outputs": [],
      "source": [
        "def interpolate_history(hist1, hist2, alpha):\n",
        "  \"\"\"\n",
        "  get the mnmx (hyperparameter bounding box) value for a fraction alpha between\n",
        "  two images\n",
        "  \"\"\"\n",
        "\n",
        "  _, mnmx1 = hist1\n",
        "  _, mnmx2 = hist2\n",
        "\n",
        "  if alpha == 0:\n",
        "    # avoid NaNs on very last frame\n",
        "    return mnmx1\n",
        "\n",
        "  w1 = np.array([mnmx1[1] - mnmx1[0], mnmx1[3] - mnmx1[2]])\n",
        "  w2 = np.array([mnmx2[1] - mnmx2[0], mnmx2[3] - mnmx2[2]])\n",
        "  c1 = np.array([(mnmx1[0] + mnmx1[1])/2, (mnmx1[2] + mnmx1[3])/2])\n",
        "  c2 = np.array([(mnmx2[0] + mnmx2[1])/2, (mnmx2[2] + mnmx2[3])/2])\n",
        "\n",
        "  gamma = np.exp((1-alpha)*0 + alpha*np.log(w2/w1))\n",
        "\n",
        "  # ct = cstar + (c1 - cstar)*gamma\n",
        "  # c1 = cstar + (c1 - cstar)*1\n",
        "  # c2 = cstar + (c1 - cstar)*w2/w1\n",
        "  cstar = (c2 - c1*w2/w1) / (1 - w2 / w1)\n",
        "\n",
        "  ct = cstar + (c1 - cstar)*gamma\n",
        "  hwt = gamma*w1\n",
        "\n",
        "  return [ct[0] - hwt[0]/2, ct[0] + hwt[0]/2, ct[1] - hwt[1]/2, ct[1] + hwt[1]/2]\n",
        "\n",
        "\n",
        "def em(extent_rev):\n",
        "  return [extent_rev[2], extent_rev[3], extent_rev[0], extent_rev[1]]\n",
        "\n",
        "def make_animator(history, timesteps_per_transition=60, reference_scale=None, cmap='Spectral'):\n",
        "\n",
        "  fig, ax, im1 = plot_img(history[0][0], history[0][1], newmnmx=None,\n",
        "                          handler=False, reference_scale=reference_scale, cmap=cmap)\n",
        "\n",
        "  im2 = ax.imshow(\n",
        "      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n",
        "      vmin = -1, vmax = 1,\n",
        "      cmap=cmap,\n",
        "      aspect='auto',\n",
        "      interpolation='nearest'\n",
        "      )\n",
        "\n",
        "  im3 = ax.imshow(\n",
        "      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n",
        "      vmin = -1, vmax = 1,\n",
        "      cmap=cmap,\n",
        "      aspect='auto',\n",
        "      interpolation='nearest'\n",
        "      )\n",
        "\n",
        "  def animate(n):\n",
        "    hist_index = n // timesteps_per_transition\n",
        "    alpha = (n % timesteps_per_transition) / timesteps_per_transition\n",
        "\n",
        "    hist1 = history[hist_index]\n",
        "    if hist_index >= len(history)-1:\n",
        "      hist2 = hist1 # very last frame\n",
        "    else:\n",
        "      hist2 = history[hist_index+1]\n",
        "    if hist_index >= len(history)-2:\n",
        "      hist3 = hist2 # very last frame\n",
        "    else:\n",
        "      hist3 = history[hist_index+2]\n",
        "\n",
        "    lims = interpolate_history(hist1, hist2, alpha)\n",
        "\n",
        "    # interpolation scheme for image restretch / colormap\n",
        "    alpha_area = jnp.sin(alpha*np.pi/2)**2\n",
        "\n",
        "    print(f'frame {n} / {timesteps_per_transition*len(history)}, zoom step {hist_index} / {len(history)}', end='\\r', flush=True)\n",
        "\n",
        "    img_1 = (1-alpha_area)*cdf_img(hist1[0], hist1[0]) + alpha_area*cdf_img(hist1[0], hist2[0])\n",
        "    img_2 = (1-alpha_area)*cdf_img(hist2[0], hist1[0]) + alpha_area*cdf_img(hist2[0], hist2[0])\n",
        "    img_3 = (1-alpha_area)*cdf_img(hist3[0], hist1[0]) + alpha_area*cdf_img(hist3[0], hist2[0])\n",
        "\n",
        "    im1.set_data(img_1)\n",
        "    im1.set_extent(em(hist1[1]))\n",
        "    im2.set_data(img_2)\n",
        "    im2.set_extent(em(hist2[1]))\n",
        "    im3.set_data(img_3)\n",
        "    im3.set_extent(em(hist3[1]))\n",
        "    im3.set_alpha(alpha)\n",
        "\n",
        "    ax.set_ylim(lims[0], lims[1])\n",
        "    ax.set_xlim(lims[2], lims[3])\n",
        "\n",
        "    # Set the new tick positions\n",
        "    ax.set_xticks(*tickslabels([lims[2], lims[3]]))\n",
        "    ax.set_yticks(*tickslabels([lims[0], lims[1]]), rotation=90)\n",
        "\n",
        "    labels = ax.get_xticklabels()\n",
        "    labels[0].set_horizontalalignment('left')\n",
        "    labels[1].set_horizontalalignment('right')\n",
        "    labels = ax.get_yticklabels()\n",
        "    labels[0].set_verticalalignment('bottom')\n",
        "    labels[1].set_verticalalignment('top')\n",
        "\n",
        "    return fig,\n",
        "\n",
        "  anim = animation.FuncAnimation(fig,animate,frames=timesteps_per_transition*(len(history)-1)+1, repeat=False)\n",
        "  return anim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy28yqH-2THl"
      },
      "source": [
        "# generate images and movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFYC655KGeOa"
      },
      "source": [
        "## ****************** Interactive exploration of fractal landscape! You will spend most of your time in this cell. ******************"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Click and drag to zoom in on parts of the image. It may take some time to recompute and update the image. You will not see the selection box while you are dragging,but the new image will be computed after you release the mouse button.\n",
        "\n",
        "If images look speckled or noisy, increase the `default_resolution` in the init cell (this will  slow down image generation).\n"
      ],
      "metadata": {
        "id": "gL8SZoP-6guW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otoF4G0aRo15"
      },
      "outputs": [],
      "source": [
        "assert interactive_gui, \"Set interactive_gui to True in the first cell, and restart the colab kernel\"\n",
        "\n",
        "plt.close('all')\n",
        "plt.ion()\n",
        "\n",
        "mnmx = [-3, 6, -3, 6]\n",
        "img = gen_img(mnmx)\n",
        "plot_img(img, mnmx, None)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-YhLFJx32q-"
      },
      "source": [
        "## Show all the generated images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnfLWH_rnSSs"
      },
      "outputs": [],
      "source": [
        "plt.close('all')\n",
        "\n",
        "for ii, impair in enumerate(image_history):\n",
        "  image, mnmx = impair\n",
        "  newmnmx = None\n",
        "  if ii < len(image_history)-1:\n",
        "    newmnmx = image_history[ii+1][1]\n",
        "  # fname = f'fractal_train_width{width}_depth{depth}_datasetparamratio{dataset_param_multiple}_minibatch{minibatch_size}_nonlinearity{nonlinearity}_step{ii}_coords{mnmx}.pdf'\n",
        "  fname = None\n",
        "  # print(ii, mnmx)\n",
        "  plot_img(image, mnmx, newmnmx=newmnmx, handler=False, savename=fname)\n",
        "  plt.title(mnmx)\n",
        "  plt.tight_layout()\n",
        "  # files.download(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LbxA51E-bb9"
      },
      "source": [
        "## generate a movie, and save the raw keyframes as a pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4VrBhxklAu8"
      },
      "outputs": [],
      "source": [
        "hist_video = zoom_out_sequence(image_history[-1], growth_factor=2.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tGWiLPlum1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9d7161-426b-4c05-b887-dfcc98df313d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "increasing resolution of 0 / 2 at 2025-07-29 18:31:39.542347, current resolution is (2, 2)\n",
            "increasing resolution of 1 / 2 at 2025-07-29 18:36:11.177392, current resolution is (512, 512)\n"
          ]
        }
      ],
      "source": [
        "# each call to increase_resolution increases the resolution of one image and\n",
        "# returns True, or returns False if all images are at or exceed the target resolution\n",
        "while increase_resolution(hist_video, 2048):\n",
        "  with open(f'/content/drive/MyDrive/fractal/{canonical_name()}.pickle', 'wb') as handle:\n",
        "      pickle.dump(hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2I8zXGijWU-"
      },
      "outputs": [],
      "source": [
        "ts = 30\n",
        "anim = make_animator(hist_video, timesteps_per_transition=ts*2)\n",
        "anim.save(f'/content/drive/MyDrive/fractal/{canonical_name()}.mp4',fps=ts, dpi=dpi)\n",
        "plt.close('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mokriqoKblBJ"
      },
      "source": [
        "# Generate the high quality images, movies, and fractal dimension estimates used in the blog post and paper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running this code, you should copy [this fractal Google Drive folder](https://drive.google.com/drive/folders/1-LKmtV1-kP-VJClHUuPlzRb2WPQMq4mx) into you own Google Drive, so you have access to the same raw data."
      ],
      "metadata": {
        "id": "aA5h2J2mMPIw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Bt69p41Eny"
      },
      "source": [
        "## convenience code to generate and save fractal images and movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr9z1_x-1D0B"
      },
      "outputs": [],
      "source": [
        "def load_and_generate(canonical=None, max_frame=999999):\n",
        "  global dpi\n",
        "  global figsize\n",
        "\n",
        "  dpi = 1000\n",
        "  figsize = (5.2,4.5)\n",
        "\n",
        "  assert not interactive_gui, \"Set interactive_gui to False in the first cell, and restart the colab kernel\"\n",
        "\n",
        "  if canonical is None:\n",
        "    canonical = canonical_name()\n",
        "\n",
        "  print(f'generating images and movie for {canonical}')\n",
        "\n",
        "  with open(f'/content/drive/MyDrive/fractal/{canonical}.pickle', 'rb') as handle:\n",
        "    hist_video = pickle.load(handle)\n",
        "\n",
        "  hist_video = hist_video[:max_frame]\n",
        "\n",
        "  # make sure we are at full resolution\n",
        "  # each call to increase_resolution increases the resolution of one image and returns True, or returns False if all images are at or exceed the targer resolution\n",
        "  while increase_resolution(hist_video, 4096):\n",
        "    with open(f'/content/drive/MyDrive/fractal/{canonical}.pickle', 'wb') as handle:\n",
        "        pickle.dump(hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  for ii, impair in enumerate(hist_video):\n",
        "    img, mnmx = impair\n",
        "    fname = f'/content/drive/MyDrive/fractal/{canonical}_step-{ii}.pdf'\n",
        "    plot_img(img, mnmx, handler=False, savename=fname, title=\"\")\n",
        "    plt.close('all')\n",
        "\n",
        "  estimate_fractal_dimension(hist_video)\n",
        "  plt.close('all')\n",
        "\n",
        "  # dpi of 1500 might seem excessive, but we need a very high resolution,\n",
        "  # otherwise we get ugly transcoding errors when we upload to vimeo or youtube\n",
        "  dpi = 1500\n",
        "  figsize = (5.5,5.5)\n",
        "  ts = 30\n",
        "  anim = make_animator(hist_video, timesteps_per_transition=int(ts*1.5))\n",
        "  fname = f'{canonical}.mp4'\n",
        "  writer=animation.FFMpegWriter(bitrate=200000, codec='hevc', fps=ts)\n",
        "  anim.save(fname, dpi=dpi, writer=writer)\n",
        "  shutil.copyfile(fname, f'/content/drive/MyDrive/fractal/{fname}')\n",
        "  plt.close('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ4UX_kEaVQP"
      },
      "source": [
        "## batch size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5XDgd1iaUzh"
      },
      "outputs": [],
      "source": [
        "interactive_gui = False\n",
        "width = 16\n",
        "depth = 2\n",
        "dataset_param_multiple = 'single_datapoint'\n",
        "minibatch_size = None\n",
        "target_dim = 1\n",
        "nonlinearity = 'tanh'\n",
        "phase_space = 'lr_vs_lr'\n",
        "readout = 'loss'\n",
        "\n",
        "load_and_generate()\n",
        "\n",
        "# zoom_sequence_width-16_depth-2_datasetparamratio-single_datapoint_minibatch-None_nonlinearity-tanh_phasespace-lr_vs_lr.pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_FXlvJ-kS__"
      },
      "source": [
        "## tanh full batch initialization shift vs learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsvTZsPp039O"
      },
      "outputs": [],
      "source": [
        "width = 16\n",
        "depth = 2\n",
        "dataset_param_multiple = 1.\n",
        "minibatch_size = None\n",
        "target_dim = 1\n",
        "nonlinearity = 'tanh'\n",
        "phase_space = 'paraminit_vs_lr'\n",
        "readout = 'loss'\n",
        "\n",
        "load_and_generate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_TTk4QOe-_O"
      },
      "source": [
        "## linear full batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWihvkk56oc6"
      },
      "outputs": [],
      "source": [
        "width = 16\n",
        "depth = 2\n",
        "dataset_param_multiple = 1.\n",
        "minibatch_size = None\n",
        "target_dim = 1\n",
        "nonlinearity = 'identity'\n",
        "phase_space = 'lr_vs_lr'\n",
        "readout = 'loss'\n",
        "\n",
        "load_and_generate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12ClNbrVE2t0"
      },
      "source": [
        "## relu full batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtRIEmzAAATJ"
      },
      "outputs": [],
      "source": [
        "width = 16\n",
        "depth = 2\n",
        "dataset_param_multiple = 1.\n",
        "minibatch_size = None\n",
        "target_dim = 1\n",
        "nonlinearity = 'relu'\n",
        "phase_space = 'lr_vs_lr'\n",
        "readout = 'loss'\n",
        "\n",
        "load_and_generate(max_frame=52)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1zsHzF--tMG"
      },
      "source": [
        "## tanh full batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAEgIMzfALze"
      },
      "outputs": [],
      "source": [
        "width = 16\n",
        "depth = 2\n",
        "dataset_param_multiple = 1.\n",
        "minibatch_size = None\n",
        "target_dim = 1\n",
        "nonlinearity = 'tanh'\n",
        "phase_space = 'lr_vs_lr'\n",
        "readout = 'loss'\n",
        "\n",
        "load_and_generate(max_frame=49)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAAiqB_fzaKm"
      },
      "source": [
        "## tanh minibatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqmj9EC_AU93"
      },
      "outputs": [],
      "source": [
        "width = 16\n",
        "depth = 2\n",
        "dataset_param_multiple = 1.\n",
        "minibatch_size = 16\n",
        "target_dim = 1\n",
        "nonlinearity = 'tanh'\n",
        "phase_space = 'lr_vs_lr'\n",
        "readout = 'loss'\n",
        "\n",
        "load_and_generate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh_YTWm3tQwo"
      },
      "source": [
        "# turn down the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GGuB_Ir3FSJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "print(\"countdown to shutdown \", datetime.datetime.now())\n",
        "\n",
        "time.sleep(3000)\n",
        "\n",
        "print(\"shutting down \", datetime.datetime.now())\n",
        "\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VGt6W9UsWI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}